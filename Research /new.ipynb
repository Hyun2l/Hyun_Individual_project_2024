{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-27T15:59:52.143375Z",
     "start_time": "2024-04-27T15:59:28.940742Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_5/533f3cq93vq25vl2f3txpkb40000gn/T/ipykernel_15899/382747998.py:125: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_combined['LapTime'].fillna(method='ffill', inplace=True)\n",
      "/var/folders/_5/533f3cq93vq25vl2f3txpkb40000gn/T/ipykernel_15899/382747998.py:125: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_combined['LapTime'].fillna(method='ffill', inplace=True)\n",
      "/var/folders/_5/533f3cq93vq25vl2f3txpkb40000gn/T/ipykernel_15899/382747998.py:127: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_combined['Position'].fillna(df_combined['Position'].mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 96556 entries, 0 to 96555\n",
      "Data columns (total 112 columns):\n",
      " #    Column                     Dtype   \n",
      "---   ------                     -----   \n",
      " 0    DriverNumber               int64   \n",
      " 1    LapTime                    float64 \n",
      " 2    LapNumber                  float64 \n",
      " 3    Stint                      float64 \n",
      " 4    SpeedI1                    float64 \n",
      " 5    SpeedI2                    float64 \n",
      " 6    SpeedFL                    float64 \n",
      " 7    SpeedST                    float64 \n",
      " 8    TyreLife                   float64 \n",
      " 9    FreshTyre                  int64   \n",
      " 10   Position                   float64 \n",
      " 11   IsAccurate                 int64   \n",
      " 12   AirTemp                    float64 \n",
      " 13   Humidity                   float64 \n",
      " 14   Pressure                   float64 \n",
      " 15   Rainfall                   float64 \n",
      " 16   TrackTemp                  float64 \n",
      " 17   WindDirection              float64 \n",
      " 18   WindSpeed                  float64 \n",
      " 19   Year                       int64   \n",
      " 20   Original_Weather_Category  object  \n",
      " 21   Weather_Category_Rainy     bool    \n",
      " 22   Weather_Category_high      bool    \n",
      " 23   Weather_Category_low       bool    \n",
      " 24   Weather_Category_medium    bool    \n",
      " 25   Weather_Category_very_low  bool    \n",
      " 26   Original_Driver            object  \n",
      " 27   Original_TrackTemp_Cat     category\n",
      " 28   TrackTemp_Cat_VERY_LOW     bool    \n",
      " 29   TrackTemp_Cat_Low          bool    \n",
      " 30   TrackTemp_Cat_Medium       bool    \n",
      " 31   TrackTemp_Cat_Warm         bool    \n",
      " 32   TrackTemp_Cat_High         bool    \n",
      " 33   TrackConditionIndex        float64 \n",
      " 34   Driver_AIT                 bool    \n",
      " 35   Driver_ALB                 bool    \n",
      " 36   Driver_ALO                 bool    \n",
      " 37   Driver_BOT                 bool    \n",
      " 38   Driver_DEV                 bool    \n",
      " 39   Driver_FIT                 bool    \n",
      " 40   Driver_GAS                 bool    \n",
      " 41   Driver_GIO                 bool    \n",
      " 42   Driver_GRO                 bool    \n",
      " 43   Driver_HAM                 bool    \n",
      " 44   Driver_HUL                 bool    \n",
      " 45   Driver_KUB                 bool    \n",
      " 46   Driver_KVY                 bool    \n",
      " 47   Driver_LAT                 bool    \n",
      " 48   Driver_LAW                 bool    \n",
      " 49   Driver_LEC                 bool    \n",
      " 50   Driver_MAG                 bool    \n",
      " 51   Driver_MAZ                 bool    \n",
      " 52   Driver_MSC                 bool    \n",
      " 53   Driver_NOR                 bool    \n",
      " 54   Driver_OCO                 bool    \n",
      " 55   Driver_PER                 bool    \n",
      " 56   Driver_PIA                 bool    \n",
      " 57   Driver_RAI                 bool    \n",
      " 58   Driver_RIC                 bool    \n",
      " 59   Driver_RUS                 bool    \n",
      " 60   Driver_SAI                 bool    \n",
      " 61   Driver_SAR                 bool    \n",
      " 62   Driver_STR                 bool    \n",
      " 63   Driver_TSU                 bool    \n",
      " 64   Driver_VER                 bool    \n",
      " 65   Driver_VET                 bool    \n",
      " 66   Driver_ZHO                 bool    \n",
      " 67   Compound_HARD              bool    \n",
      " 68   Compound_INTERMEDIATE      bool    \n",
      " 69   Compound_MEDIUM            bool    \n",
      " 70   Compound_SOFT              bool    \n",
      " 71   Compound_UNKNOWN           bool    \n",
      " 72   Compound_WET               bool    \n",
      " 73   Team_Alfa Romeo            bool    \n",
      " 74   Team_Alfa Romeo Racing     bool    \n",
      " 75   Team_AlphaTauri            bool    \n",
      " 76   Team_Alpine                bool    \n",
      " 77   Team_Aston Martin          bool    \n",
      " 78   Team_Ferrari               bool    \n",
      " 79   Team_Haas F1 Team          bool    \n",
      " 80   Team_McLaren               bool    \n",
      " 81   Team_Mercedes              bool    \n",
      " 82   Team_Racing Point          bool    \n",
      " 83   Team_Red Bull Racing       bool    \n",
      " 84   Team_Renault               bool    \n",
      " 85   Team_Toro Rosso            bool    \n",
      " 86   Team_Williams              bool    \n",
      " 87   TrackStatus_1.0            bool    \n",
      " 88   TrackStatus_2.0            bool    \n",
      " 89   TrackStatus_4.0            bool    \n",
      " 90   TrackStatus_5.0            bool    \n",
      " 91   TrackStatus_6.0            bool    \n",
      " 92   TrackStatus_7.0            bool    \n",
      " 93   TrackStatus_24.0           bool    \n",
      " 94   TrackStatus_25.0           bool    \n",
      " 95   TrackStatus_26.0           bool    \n",
      " 96   TrackStatus_42.0           bool    \n",
      " 97   TrackStatus_45.0           bool    \n",
      " 98   TrackStatus_52.0           bool    \n",
      " 99   TrackStatus_54.0           bool    \n",
      " 100  TrackStatus_64.0           bool    \n",
      " 101  TrackStatus_65.0           bool    \n",
      " 102  TrackStatus_67.0           bool    \n",
      " 103  TrackStatus_72.0           bool    \n",
      " 104  TrackStatus_245.0          bool    \n",
      " 105  TrackStatus_264.0          bool    \n",
      " 106  TrackStatus_265.0          bool    \n",
      " 107  TrackStatus_267.0          bool    \n",
      " 108  TrackStatus_672.0          bool    \n",
      " 109  TrackStatus_724.0          bool    \n",
      " 110  TrackStatus_6724.0         bool    \n",
      " 111  IsRainy                    int64   \n",
      "dtypes: bool(87), category(1), float64(17), int64(5), object(2)\n",
      "memory usage: 25.8+ MB\n",
      "Iterative Imputation MSE: 4.449080787217964 R2: 0.9737704006303504\n",
      "Mean Imputation MSE: 4.082390660402454 R2: 0.9759322258655336\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from xgboost import XGBRegressor\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "# Load dataset\n",
    "df = pd.read_csv('f1_2019_to_2023_all_drivers_all_data.csv', low_memory=False)\n",
    "\n",
    "# Convert time columns to seconds\n",
    "time_columns = ['LapTime', 'Sector1Time', 'Sector2Time', 'Sector3Time']\n",
    "for col in time_columns:\n",
    "    df[col] = pd.to_timedelta(df[col]).dt.total_seconds()\n",
    "\n",
    "# Convert binary columns to integer type\n",
    "df['Rainfall'] = df['Rainfall'].astype(int)\n",
    "df['FreshTyre'] = df['FreshTyre'].astype(int)\n",
    "df['IsAccurate'] = df['IsAccurate'].astype(int)\n",
    "\n",
    "\n",
    "# Categorize weather condition based on centroid values of Kmeans clustering\n",
    "def categorize_weather(row):\n",
    "    if row['Rainfall'] > 0:\n",
    "        return 'Rainy'\n",
    "    elif row['AirTemp'] > 28.43213126:\n",
    "        return 'high'\n",
    "    elif row['AirTemp'] > 21.31279265:\n",
    "        return 'medium'\n",
    "    elif row['AirTemp'] > 12.84901403:\n",
    "        return 'low'\n",
    "    else:\n",
    "        return 'very_low'\n",
    "\n",
    "df['Weather_Category'] = df.apply(categorize_weather, axis=1)\n",
    "df['Original_Weather_Category'] = df['Weather_Category']\n",
    "df = pd.get_dummies(df, columns=['Weather_Category'])\n",
    "\n",
    "\n",
    "# Keep the original Driver and Circuit for EDA\n",
    "df['Original_Driver'] = df['Driver']\n",
    "\n",
    "# Create Track temperature category based on the result of Kmeans clustering \n",
    "df['TrackTemp_Cat'] = pd.cut(df['TrackTemp'], bins=[0, 18.96764999, 27.87457484, 35.04425766, 41.75142602, 50.51006013], labels=['VERY_LOW', 'Low', 'Medium', 'Warm', 'High'])\n",
    "df['Original_TrackTemp_Cat'] = df['TrackTemp_Cat']\n",
    "df = pd.get_dummies(df, columns=['TrackTemp_Cat'])\n",
    "\n",
    "\n",
    "#Feature Engineering with weather condition features\n",
    "df['TrackConditionIndex'] = (df['AirTemp'] + df['TrackTemp'] + df['Humidity'] + df['Pressure'] +\n",
    "                             df['WindSpeed'] + df['Rainfall']) / 6\n",
    "\n",
    "# One-hot encoding\n",
    "df = pd.get_dummies(df, columns=['Driver', 'Compound', 'Team','TrackStatus'])\n",
    "\n",
    "# Drop irrelevant columns\n",
    "columns_to_drop = ['Time', 'Sector1SessionTime', 'Sector2SessionTime', 'Sector3SessionTime',\n",
    "                   'PitOutTime', 'PitInTime', 'LapStartDate', 'Deleted', 'DeletedReason', 'FastF1Generated',\n",
    "                   'IsPersonalBest', 'Sector3Time','LapStartTime','Sector2Time','Sector1Time','Circuit']\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "\n",
    "# Select numerical values for scaling and imputation\n",
    "numeric_features = ['Humidity', 'Pressure', 'WindDirection', 'WindSpeed','TrackTemp','AirTemp','TrackConditionIndex','Rainfall','SpeedI1', 'SpeedI2', 'SpeedFL', 'SpeedST']\n",
    "\n",
    "\n",
    "## Separate Rainy / dry days ##\n",
    "# 1. Separate LapTime as dry or wet(rainy) condition ( since lapTime of rainy day would be recognized as outliers)\n",
    "# 2. Remove Outliers for dry condition LapTime\n",
    "# 3. Build Combined LapTime df (Outliers for dry days are deleted)\n",
    "\n",
    "# Flag for rainy conditions\n",
    "df['IsRainy'] = df['Rainfall'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Separate dataframes for dry and wet conditions\n",
    "df_dry = df[df['IsRainy'] == 0]\n",
    "df_wet = df[df['IsRainy'] == 1]\n",
    "\n",
    "# Remove Outliers for dry days using the IQR method that effective to removes extreme outliers\n",
    "Q1_dry = df_dry['LapTime'].quantile(0.25)\n",
    "Q3_dry = df_dry['LapTime'].quantile(0.75)\n",
    "IQR_dry = Q3_dry - Q1_dry\n",
    "lower_bound_dry = Q1_dry - 1.5 * IQR_dry\n",
    "upper_bound_dry = Q3_dry + 1.5 * IQR_dry\n",
    "df_dry_filtered = df_dry[(df_dry['LapTime'] >= lower_bound_dry) & (df_dry['LapTime'] <= upper_bound_dry)]\n",
    "df_dry_filtered = df_dry_filtered.copy()\n",
    "df_wet = df_wet.copy()\n",
    "\n",
    "\n",
    "from fancyimpute import IterativeImputer as MICE\n",
    "\n",
    "\n",
    "mice_imputer = MICE()\n",
    "df_imputed = mice_imputer.fit_transform(df)\n",
    "\n",
    "\n",
    "\n",
    "## Scaling to the selected numeric features ##\n",
    "robust_scaler = RobustScaler()\n",
    "\n",
    "# Applying scaling to the numeric features\n",
    "df_dry_filtered[numeric_features] = robust_scaler.fit_transform(df_dry_filtered[numeric_features])\n",
    "df_wet[numeric_features] = robust_scaler.transform(df_wet[numeric_features])  # Use transform, not fit_transform\n",
    "\n",
    "# Combining the datasets after scaling\n",
    "df_combined = pd.concat([df_dry_filtered, df_wet], ignore_index=True)\n",
    "\n",
    "\n",
    "# Remove rows where 'Position' column contains NaN\n",
    "df_combined['LapTime'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "df_combined['Position'].fillna(df_combined['Position'].mean(), inplace=True)\n",
    "\n",
    "df_combined.info(verbose=True)\n",
    "\n",
    "\n",
    "# Drop Strings columns\n",
    "df_combined = df_combined.drop(['Original_Driver', 'Original_Weather_Category', 'Original_TrackTemp_Cat'], axis=1)\n",
    "# Define function to compare the impact of different imputation methods\n",
    "def model_performance_comparison(df, numeric_features, target_column):\n",
    "    # Prepare data for modeling\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the imputers\n",
    "    imp_iterative = IterativeImputer(random_state=42)\n",
    "    imp_mean = SimpleImputer(strategy='mean')\n",
    "\n",
    "    # Fit and transform the training data using both imputers\n",
    "    X_train_iterative = imp_iterative.fit_transform(X_train[numeric_features])\n",
    "    X_train_mean = imp_mean.fit_transform(X_train[numeric_features])\n",
    "\n",
    "    # Prepare complete training dataframes including non-numeric features\n",
    "    X_train_iterative = np.concatenate((X_train_iterative, X_train.drop(columns=numeric_features).values), axis=1)\n",
    "    X_train_mean = np.concatenate((X_train_mean, X_train.drop(columns=numeric_features).values), axis=1)\n",
    "\n",
    "    # Transform the test data (do not fit the imputer to avoid data leakage)\n",
    "    X_test_iterative = imp_iterative.transform(X_test[numeric_features])\n",
    "    X_test_mean = imp_mean.transform(X_test[numeric_features])\n",
    "    X_test_iterative = np.concatenate((X_test_iterative, X_test.drop(columns=numeric_features).values), axis=1)\n",
    "    X_test_mean = np.concatenate((X_test_mean, X_test.drop(columns=numeric_features).values), axis=1)\n",
    "\n",
    "    # Define and fit the XGBoost model on both datasets\n",
    "    model_iterative = XGBRegressor(random_state=42)\n",
    "    model_mean = XGBRegressor(random_state=42)\n",
    "    model_iterative.fit(X_train_iterative, y_train)\n",
    "    model_mean.fit(X_train_mean, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred_iterative = model_iterative.predict(X_test_iterative)\n",
    "    y_pred_mean = model_mean.predict(X_test_mean)\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    mse_iterative = mean_squared_error(y_test, y_pred_iterative)\n",
    "    mse_mean = mean_squared_error(y_test, y_pred_mean)\n",
    "    r2_iterative = r2_score(y_test, y_pred_iterative)\n",
    "    r2_mean = r2_score(y_test, y_pred_mean)\n",
    "\n",
    "    # Print the performance metrics\n",
    "    print(\"Iterative Imputation MSE:\", mse_iterative, \"R2:\", r2_iterative)\n",
    "    print(\"Mean Imputation MSE:\", mse_mean, \"R2:\", r2_mean)\n",
    "\n",
    "# Example usage\n",
    "model_performance_comparison(df_combined, numeric_features, 'LapTime')\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IterativeImputer is experimental and the API might change without any deprecation cycle. To use it, you need to explicitly import enable_iterative_imputer:\nfrom sklearn.experimental import enable_iterative_imputer",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m mean_squared_error, r2_score\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mxgboost\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m XGBRegressor\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimpute\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m IterativeImputer, SimpleImputer\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m RobustScaler\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m train_test_split, KFold, GridSearchCV\n",
      "File \u001B[0;32m/opt/anaconda3/envs/COMS30035_labs/lib/python3.11/site-packages/sklearn/impute/__init__.py:18\u001B[0m, in \u001B[0;36m__getattr__\u001B[0;34m(name)\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getattr__\u001B[39m(name):\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIterativeImputer\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m---> 18\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[1;32m     19\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is experimental and the API might change without any \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     20\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdeprecation cycle. To use it, you need to explicitly import \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     21\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124menable_iterative_imputer:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     22\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfrom sklearn.experimental import enable_iterative_imputer\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     23\u001B[0m         )\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodule \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m has no attribute \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mImportError\u001B[0m: IterativeImputer is experimental and the API might change without any deprecation cycle. To use it, you need to explicitly import enable_iterative_imputer:\nfrom sklearn.experimental import enable_iterative_imputer"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T15:56:05.537367Z",
     "start_time": "2024-04-27T15:56:05.212059Z"
    }
   },
   "id": "b3b6e190e23150a0",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f03465ab518b309d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
