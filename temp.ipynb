{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('f1_2019_to_2022_all_drivers_all_data.csv', low_memory=False)\n",
    "\n",
    "# Convert time columns to seconds\n",
    "time_columns = ['LapTime', 'Sector1Time', 'Sector2Time', 'Sector3Time']\n",
    "for col in time_columns:\n",
    "    df[col] = pd.to_timedelta(df[col]).dt.total_seconds()\n",
    "\n",
    "# Convert binary columns to integer type\n",
    "df['Rainfall'] = df['Rainfall'].astype(int)\n",
    "df['FreshTyre'] = df['FreshTyre'].astype(int)\n",
    "df['IsAccurate'] = df['IsAccurate'].astype(int)\n",
    "\n",
    "\n",
    "# Feature Engineering: \n",
    "\n",
    "# Categorize weather and return numerical labels for models Initial: 0 , 25 , 19 \n",
    "def categorize_weather(row):\n",
    "    if row['Rainfall'] > 0:\n",
    "        return 'Rainy'\n",
    "    elif row['AirTemp'] > 27:\n",
    "        return 'Hot'\n",
    "    elif row['AirTemp'] > 20:\n",
    "        return 'Warm'\n",
    "    else:\n",
    "        return 'Cool'\n",
    "df['Weather_Category'] = df.apply(categorize_weather, axis=1)\n",
    "\n",
    "df = pd.get_dummies(df, columns=['Weather_Category'])\n",
    "\n",
    "# Create Track temperature category based on the result of clustering \n",
    "df['TrackTemp_Cat'] = pd.cut(df['TrackTemp'], bins=[18, 27, 34, 41, 50, np.inf], labels=['VERY_LOW', 'Low', 'Medium', 'High', 'VERY_HIGH'])\n",
    "\n",
    "# Initial values : [10, 20, 30, 40, 45, np.inf], labels=['VERY_LOW', 'Low', 'Medium', 'High', 'VERY_HIGH'])\n",
    "df = pd.get_dummies(df, columns=['TrackTemp_Cat'])\n",
    "\n",
    "# Tyre Age Interaction with TrackTemp \n",
    "df['TyreAge_TrackTemp'] = df['TyreLife'] * df['TrackTemp']\n",
    "\n",
    "\n",
    "# One-hot encoding\n",
    "df = pd.get_dummies(df, columns=['Driver', 'Circuit', 'Compound', 'Team'])\n",
    "\n",
    "\n",
    "# Drop irrelevant columns\n",
    "columns_to_drop = ['Time', 'LapStartTime', 'Sector1SessionTime', 'Sector2SessionTime', 'Sector3SessionTime',\n",
    "                   'PitOutTime', 'PitInTime', 'LapStartDate', 'Deleted', 'DeletedReason', 'FastF1Generated',\n",
    "                   'IsPersonalBest', 'Sector3Time', 'Sector2Time', 'Sector1Time']\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T16:36:01.775282Z",
     "start_time": "2024-04-15T16:36:00.256393Z"
    }
   },
   "id": "9a79f732f3fc07b7",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "# Initialize Iterative Imputer with a simpler model for numeric features\n",
    "iterative_imputer = IterativeImputer(estimator=BayesianRidge(), random_state=42)\n",
    "numeric_features = ['SpeedI1', 'SpeedI2', 'SpeedFL', 'SpeedST', 'AirTemp', 'Humidity', 'Pressure', 'TrackTemp', 'WindDirection', 'WindSpeed']\n",
    "\n",
    "# Impute and scale numeric features\n",
    "df[numeric_features] = iterative_imputer.fit_transform(df[numeric_features])\n",
    "\n",
    "\n",
    "features_to_scale = ['AirTemp', 'Humidity', 'Pressure', 'TrackTemp']\n",
    "robust_scaler = RobustScaler()\n",
    "df[features_to_scale] = robust_scaler.fit_transform(df[features_to_scale])\n",
    "\n",
    "iterative_imputer = IterativeImputer(estimator=RandomForestRegressor(n_jobs=-1),max_iter=20, random_state=42)\n",
    "\n",
    "# Interpolate LapTime separately considering its sequential nature\n",
    "# df['LapTime'] = df['LapTime'].interpolate(method='Ran')\n",
    "\n",
    "df['LapTime'] = iterative_imputer.fit_transform(df['LapTime'].values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T16:36:03.192149Z",
     "start_time": "2024-04-15T16:36:01.776224Z"
    }
   },
   "id": "afde45289ccbc8e2",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "\"# Initialize Iterative Imputer\\n\\niterative_imputer = IterativeImputer(estimator=RandomForestRegressor(n_jobs=-1),max_iter=20, random_state=42)\\nnumeric_features = ['AirTemp', 'Humidity', 'Pressure', 'TrackTemp','LapTime']\\n\\ndf[numeric_features] = iterative_imputer.fit_transform(df[numeric_features])\\n\\nfeatures_to_scale = ['AirTemp', 'Humidity', 'Pressure', 'TrackTemp']\\n\\n# Initialize the RobustScaler\\nrobust_scaler = RobustScaler()\\n\\n# Apply scaling to the selected features\\ndf[features_to_scale] = robust_scaler.fit_transform(df[features_to_scale])\\n\\n\\n\""
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Initialize Iterative Imputer\n",
    "\n",
    "iterative_imputer = IterativeImputer(estimator=RandomForestRegressor(n_jobs=-1),max_iter=20, random_state=42)\n",
    "numeric_features = ['AirTemp', 'Humidity', 'Pressure', 'TrackTemp','LapTime']\n",
    "\n",
    "df[numeric_features] = iterative_imputer.fit_transform(df[numeric_features])\n",
    "\n",
    "features_to_scale = ['AirTemp', 'Humidity', 'Pressure', 'TrackTemp']\n",
    "\n",
    "# Initialize the RobustScaler\n",
    "robust_scaler = RobustScaler()\n",
    "\n",
    "# Apply scaling to the selected features\n",
    "df[features_to_scale] = robust_scaler.fit_transform(df[features_to_scale])\n",
    "\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T16:36:03.206290Z",
     "start_time": "2024-04-15T16:36:03.195655Z"
    }
   },
   "id": "45f0cdfa129efe1a",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T16:36:03.214507Z",
     "start_time": "2024-04-15T16:36:03.211165Z"
    }
   },
   "id": "17b787d354b4cd30",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T16:36:03.219615Z",
     "start_time": "2024-04-15T16:36:03.216632Z"
    }
   },
   "id": "71a0e8e9647c098b",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T16:36:03.224842Z",
     "start_time": "2024-04-15T16:36:03.221842Z"
    }
   },
   "id": "769ffe2329ea63e0",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Handling LapTime based on weather conditions\n",
    "df['IsRainy'] = df['Rainfall'].apply(lambda x: 1 if x > 0 else 0)\n",
    "df_dry = df[df['IsRainy'] == 0]\n",
    "df_wet = df[df['IsRainy'] == 1]\n",
    "\n",
    "# Remove outliers for dry conditions using IQR\n",
    "Q1_dry = df_dry['LapTime'].quantile(0.25)\n",
    "Q3_dry = df_dry['LapTime'].quantile(0.75)\n",
    "IQR_dry = Q3_dry - Q1_dry\n",
    "lower_bound_dry = Q1_dry - 1.5 * IQR_dry\n",
    "upper_bound_dry = Q3_dry + 1.5 * IQR_dry\n",
    "df_dry_filtered = df_dry[(df_dry['LapTime'] >= lower_bound_dry) & (df_dry['LapTime'] <= upper_bound_dry)]\n",
    "\n",
    "# Re-combine the dry and wet dataframes\n",
    "df_combined = pd.concat([df_dry_filtered, df_wet], ignore_index=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T16:36:03.314458Z",
     "start_time": "2024-04-15T16:36:03.228034Z"
    }
   },
   "id": "4d10a4d59dd17b9d",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.5370010859272427\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Splitting data into features and target\n",
    "X = df_combined.drop(['LapTime'], axis=1)\n",
    "y = df_combined['LapTime']\n",
    "\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model training with XGBoost\n",
    "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42, n_jobs=-1)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "predictions = xgb_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"RMSE: {rmse}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T16:36:04.053677Z",
     "start_time": "2024-04-15T16:36:03.317335Z"
    }
   },
   "id": "f5bc681b1f6c5bd6",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RMSE: 2.367, Std: 0.049\n",
      "CV MAE: 1.243, Std: 0.020\n",
      "CV RÂ²: 0.970, Std: 0.001\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "need to call fit or load_model beforehand",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotFittedError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 23\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCV RÂ²: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcv_r2\u001B[38;5;241m.\u001B[39mmean()\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.3f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Std: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcv_r2\u001B[38;5;241m.\u001B[39mstd()\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.3f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# Shows Important features\u001B[39;00m\n\u001B[0;32m---> 23\u001B[0m importance \u001B[38;5;241m=\u001B[39m \u001B[43mxgb_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeature_importances_\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# Sort the feature importance\u001B[39;00m\n\u001B[1;32m     26\u001B[0m sorted_indices \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margsort(importance)[::\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[0;32m/opt/anaconda3/envs/COMS30035_labs/lib/python3.11/site-packages/xgboost/sklearn.py:1314\u001B[0m, in \u001B[0;36mXGBModel.feature_importances_\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1299\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[1;32m   1300\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfeature_importances_\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m np\u001B[38;5;241m.\u001B[39mndarray:\n\u001B[1;32m   1301\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Feature importances property, return depends on `importance_type`\u001B[39;00m\n\u001B[1;32m   1302\u001B[0m \u001B[38;5;124;03m    parameter. When model trained with multi-class/multi-label/multi-target dataset,\u001B[39;00m\n\u001B[1;32m   1303\u001B[0m \u001B[38;5;124;03m    the feature importance is \"averaged\" over all targets. The \"average\" is defined\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1312\u001B[0m \n\u001B[1;32m   1313\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1314\u001B[0m     b: Booster \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_booster\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdft\u001B[39m() \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[1;32m   1317\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mweight\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbooster \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgblinear\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgain\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/COMS30035_labs/lib/python3.11/site-packages/xgboost/sklearn.py:725\u001B[0m, in \u001B[0;36mXGBModel.get_booster\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    722\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__sklearn_is_fitted__():\n\u001B[1;32m    723\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexceptions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m NotFittedError\n\u001B[0;32m--> 725\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m NotFittedError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mneed to call fit or load_model beforehand\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    726\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_Booster\n",
      "\u001B[0;31mNotFittedError\u001B[0m: need to call fit or load_model beforehand"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# Prepare the data\n",
    "X = df_dry_filtered.drop(['LapTime'], axis=1)\n",
    "y = df_dry_filtered['LapTime']\n",
    "\n",
    "# Initialize the cross-validation method\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize the model\n",
    "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_rmse = cross_val_score(xgb_model, X, y, cv=kf, scoring='neg_root_mean_squared_error')\n",
    "cv_mae = cross_val_score(xgb_model, X, y, cv=kf, scoring='neg_mean_absolute_error')\n",
    "cv_r2 = cross_val_score(xgb_model, X, y, cv=kf, scoring='r2')\n",
    "\n",
    "print(f\"CV RMSE: {-cv_rmse.mean():.3f}, Std: {cv_rmse.std():.3f}\")\n",
    "print(f\"CV MAE: {-cv_mae.mean():.3f}, Std: {cv_mae.std():.3f}\")\n",
    "print(f\"CV RÂ²: {cv_r2.mean():.3f}, Std: {cv_r2.std():.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Shows Important features\n",
    "importance = xgb_model.feature_importances_\n",
    "\n",
    "# Sort the feature importance\n",
    "sorted_indices = np.argsort(importance)[::-1]\n",
    "\n",
    "for index in sorted_indices:\n",
    "    print(f\"{X_train.columns[index]}: {importance[index]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T16:38:26.181849Z",
     "start_time": "2024-04-15T16:38:17.423520Z"
    }
   },
   "id": "c6d4a51c506e842",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# Prepare the data\n",
    "X = df_dry_filtered.drop(['LapTime'], axis=1)\n",
    "y = df_dry_filtered['LapTime']\n",
    "\n",
    "# Initialize the cross-validation method\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize the model\n",
    "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_rmse = cross_val_score(xgb_model, X, y, cv=kf, scoring='neg_root_mean_squared_error')\n",
    "cv_mae = cross_val_score(xgb_model, X, y, cv=kf, scoring='neg_mean_absolute_error')\n",
    "cv_r2 = cross_val_score(xgb_model, X, y, cv=kf, scoring='r2')\n",
    "\n",
    "print(f\"CV RMSE: {-cv_rmse.mean():.3f}, Std: {cv_rmse.std():.3f}\")\n",
    "print(f\"CV MAE: {-cv_mae.mean():.3f}, Std: {cv_mae.std():.3f}\")\n",
    "print(f\"CV RÂ²: {cv_r2.mean():.3f}, Std: {cv_r2.std():.3f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T16:36:12.643962Z",
     "start_time": "2024-04-15T16:36:12.642403Z"
    }
   },
   "id": "499062e49bff8963",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "de960b04d490a808"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "need to call fit or load_model beforehand",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotFittedError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Shows Important features\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m importance \u001B[38;5;241m=\u001B[39m \u001B[43mxgb_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeature_importances_\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Sort the feature importance\u001B[39;00m\n\u001B[1;32m      5\u001B[0m sorted_indices \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margsort(importance)[::\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[0;32m/opt/anaconda3/envs/COMS30035_labs/lib/python3.11/site-packages/xgboost/sklearn.py:1314\u001B[0m, in \u001B[0;36mXGBModel.feature_importances_\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1299\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[1;32m   1300\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfeature_importances_\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m np\u001B[38;5;241m.\u001B[39mndarray:\n\u001B[1;32m   1301\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Feature importances property, return depends on `importance_type`\u001B[39;00m\n\u001B[1;32m   1302\u001B[0m \u001B[38;5;124;03m    parameter. When model trained with multi-class/multi-label/multi-target dataset,\u001B[39;00m\n\u001B[1;32m   1303\u001B[0m \u001B[38;5;124;03m    the feature importance is \"averaged\" over all targets. The \"average\" is defined\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1312\u001B[0m \n\u001B[1;32m   1313\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1314\u001B[0m     b: Booster \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_booster\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdft\u001B[39m() \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[1;32m   1317\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mweight\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbooster \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgblinear\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgain\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/COMS30035_labs/lib/python3.11/site-packages/xgboost/sklearn.py:725\u001B[0m, in \u001B[0;36mXGBModel.get_booster\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    722\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__sklearn_is_fitted__():\n\u001B[1;32m    723\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexceptions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m NotFittedError\n\u001B[0;32m--> 725\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m NotFittedError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mneed to call fit or load_model beforehand\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    726\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_Booster\n",
      "\u001B[0;31mNotFittedError\u001B[0m: need to call fit or load_model beforehand"
     ]
    }
   ],
   "source": [
    "# Shows Important features\n",
    "importance = xgb_model.feature_importances_\n",
    "\n",
    "# Sort the feature importance\n",
    "sorted_indices = np.argsort(importance)[::-1]\n",
    "\n",
    "for index in sorted_indices:\n",
    "    print(f\"{X_train.columns[index]}: {importance[index]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T16:38:01.973416Z",
     "start_time": "2024-04-15T16:38:01.953340Z"
    }
   },
   "id": "5c9771211692b163",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model parameters: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n",
      "Best CV RMSE: 1.7646982067074881\n",
      "Best CV MAE: 0.8009456437675271\n",
      "Best CV RÂ²: 0.9833476224736895\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Prepare the data\n",
    "X = df_dry_filtered.drop(['LapTime'], axis=1)\n",
    "y = df_dry_filtered['LapTime']\n",
    "\n",
    "# Initialize the cross-validation method\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the model\n",
    "xgb = XGBRegressor(random_state=42)\n",
    "\n",
    "# Set up the hyperparameters to test\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# Custom scorer for negative RMSE\n",
    "neg_rmse_scorer = make_scorer(mean_squared_error, greater_is_better=False, squared=False)\n",
    "\n",
    "# Setup the grid search with multiple scorings\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=kf,\n",
    "                           scoring={'RMSE': neg_rmse_scorer, 'MAE': 'neg_mean_absolute_error', 'R2': 'r2'},\n",
    "                           refit='RMSE')\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Get the best model and print results\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best model parameters:\", grid_search.best_params_)\n",
    "print(\"Best CV RMSE:\", -grid_search.cv_results_['mean_test_RMSE'].max())\n",
    "print(\"Best CV MAE:\", -grid_search.cv_results_['mean_test_MAE'].max())\n",
    "print(\"Best CV RÂ²:\", grid_search.cv_results_['mean_test_R2'].max())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T16:45:14.692178Z",
     "start_time": "2024-04-15T16:42:11.768388Z"
    }
   },
   "id": "21ae3916b62329f7",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9d74f6e323ec3326"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
