{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-03T10:47:35.651669Z",
     "start_time": "2024-05-03T10:47:33.666521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 96556 entries, 0 to 96555\n",
      "Data columns (total 112 columns):\n",
      " #    Column                     Dtype   \n",
      "---   ------                     -----   \n",
      " 0    DriverNumber               int64   \n",
      " 1    LapTime                    float64 \n",
      " 2    LapNumber                  float64 \n",
      " 3    Stint                      float64 \n",
      " 4    SpeedI1                    float64 \n",
      " 5    SpeedI2                    float64 \n",
      " 6    SpeedFL                    float64 \n",
      " 7    SpeedST                    float64 \n",
      " 8    TyreLife                   float64 \n",
      " 9    FreshTyre                  int64   \n",
      " 10   Position                   float64 \n",
      " 11   IsAccurate                 int64   \n",
      " 12   AirTemp                    float64 \n",
      " 13   Humidity                   float64 \n",
      " 14   Pressure                   float64 \n",
      " 15   Rainfall                   float64 \n",
      " 16   TrackTemp                  float64 \n",
      " 17   WindDirection              float64 \n",
      " 18   WindSpeed                  float64 \n",
      " 19   Year                       int64   \n",
      " 20   Original_Weather_Category  object  \n",
      " 21   Weather_Category_Rainy     bool    \n",
      " 22   Weather_Category_high      bool    \n",
      " 23   Weather_Category_low       bool    \n",
      " 24   Weather_Category_medium    bool    \n",
      " 25   Weather_Category_very_low  bool    \n",
      " 26   Original_Driver            object  \n",
      " 27   Original_TrackTemp_Cat     category\n",
      " 28   TrackTemp_Cat_VERY_LOW     bool    \n",
      " 29   TrackTemp_Cat_Low          bool    \n",
      " 30   TrackTemp_Cat_Medium       bool    \n",
      " 31   TrackTemp_Cat_Warm         bool    \n",
      " 32   TrackTemp_Cat_High         bool    \n",
      " 33   TrackConditionIndex        float64 \n",
      " 34   Driver_AIT                 bool    \n",
      " 35   Driver_ALB                 bool    \n",
      " 36   Driver_ALO                 bool    \n",
      " 37   Driver_BOT                 bool    \n",
      " 38   Driver_DEV                 bool    \n",
      " 39   Driver_FIT                 bool    \n",
      " 40   Driver_GAS                 bool    \n",
      " 41   Driver_GIO                 bool    \n",
      " 42   Driver_GRO                 bool    \n",
      " 43   Driver_HAM                 bool    \n",
      " 44   Driver_HUL                 bool    \n",
      " 45   Driver_KUB                 bool    \n",
      " 46   Driver_KVY                 bool    \n",
      " 47   Driver_LAT                 bool    \n",
      " 48   Driver_LAW                 bool    \n",
      " 49   Driver_LEC                 bool    \n",
      " 50   Driver_MAG                 bool    \n",
      " 51   Driver_MAZ                 bool    \n",
      " 52   Driver_MSC                 bool    \n",
      " 53   Driver_NOR                 bool    \n",
      " 54   Driver_OCO                 bool    \n",
      " 55   Driver_PER                 bool    \n",
      " 56   Driver_PIA                 bool    \n",
      " 57   Driver_RAI                 bool    \n",
      " 58   Driver_RIC                 bool    \n",
      " 59   Driver_RUS                 bool    \n",
      " 60   Driver_SAI                 bool    \n",
      " 61   Driver_SAR                 bool    \n",
      " 62   Driver_STR                 bool    \n",
      " 63   Driver_TSU                 bool    \n",
      " 64   Driver_VER                 bool    \n",
      " 65   Driver_VET                 bool    \n",
      " 66   Driver_ZHO                 bool    \n",
      " 67   Compound_HARD              bool    \n",
      " 68   Compound_INTERMEDIATE      bool    \n",
      " 69   Compound_MEDIUM            bool    \n",
      " 70   Compound_SOFT              bool    \n",
      " 71   Compound_UNKNOWN           bool    \n",
      " 72   Compound_WET               bool    \n",
      " 73   Team_Alfa Romeo            bool    \n",
      " 74   Team_Alfa Romeo Racing     bool    \n",
      " 75   Team_AlphaTauri            bool    \n",
      " 76   Team_Alpine                bool    \n",
      " 77   Team_Aston Martin          bool    \n",
      " 78   Team_Ferrari               bool    \n",
      " 79   Team_Haas F1 Team          bool    \n",
      " 80   Team_McLaren               bool    \n",
      " 81   Team_Mercedes              bool    \n",
      " 82   Team_Racing Point          bool    \n",
      " 83   Team_Red Bull Racing       bool    \n",
      " 84   Team_Renault               bool    \n",
      " 85   Team_Toro Rosso            bool    \n",
      " 86   Team_Williams              bool    \n",
      " 87   TrackStatus_1.0            bool    \n",
      " 88   TrackStatus_2.0            bool    \n",
      " 89   TrackStatus_4.0            bool    \n",
      " 90   TrackStatus_5.0            bool    \n",
      " 91   TrackStatus_6.0            bool    \n",
      " 92   TrackStatus_7.0            bool    \n",
      " 93   TrackStatus_24.0           bool    \n",
      " 94   TrackStatus_25.0           bool    \n",
      " 95   TrackStatus_26.0           bool    \n",
      " 96   TrackStatus_42.0           bool    \n",
      " 97   TrackStatus_45.0           bool    \n",
      " 98   TrackStatus_52.0           bool    \n",
      " 99   TrackStatus_54.0           bool    \n",
      " 100  TrackStatus_64.0           bool    \n",
      " 101  TrackStatus_65.0           bool    \n",
      " 102  TrackStatus_67.0           bool    \n",
      " 103  TrackStatus_72.0           bool    \n",
      " 104  TrackStatus_245.0          bool    \n",
      " 105  TrackStatus_264.0          bool    \n",
      " 106  TrackStatus_265.0          bool    \n",
      " 107  TrackStatus_267.0          bool    \n",
      " 108  TrackStatus_672.0          bool    \n",
      " 109  TrackStatus_724.0          bool    \n",
      " 110  TrackStatus_6724.0         bool    \n",
      " 111  IsRainy                    int64   \n",
      "dtypes: bool(87), category(1), float64(17), int64(5), object(2)\n",
      "memory usage: 25.8+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_5/533f3cq93vq25vl2f3txpkb40000gn/T/ipykernel_24409/1126715364.py:74: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[numeric_features] = df[numeric_features].fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from xgboost import XGBRegressor\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('f1_2019_to_2023_all_drivers_all_data.csv', low_memory=False)\n",
    "\n",
    "# Convert time columns to seconds\n",
    "time_columns = ['LapTime', 'Sector1Time', 'Sector2Time', 'Sector3Time']\n",
    "for col in time_columns:\n",
    "    df[col] = pd.to_timedelta(df[col]).dt.total_seconds()\n",
    "\n",
    "# Convert binary columns to integer type\n",
    "df['Rainfall'] = df['Rainfall'].astype(int)\n",
    "df['FreshTyre'] = df['FreshTyre'].astype(int)\n",
    "df['IsAccurate'] = df['IsAccurate'].astype(int)\n",
    "\n",
    "\n",
    "# Categorize weather condition based on centroid values of Kmeans clustering\n",
    "def categorize_weather(row):\n",
    "    if row['Rainfall'] > 0:\n",
    "        return 'Rainy'\n",
    "    elif row['AirTemp'] > 28.43213126:\n",
    "        return 'high'\n",
    "    elif row['AirTemp'] > 21.31279265:\n",
    "        return 'medium'\n",
    "    elif row['AirTemp'] > 12.84901403:\n",
    "        return 'low'\n",
    "    else:\n",
    "        return 'very_low'\n",
    "\n",
    "df['Weather_Category'] = df.apply(categorize_weather, axis=1)\n",
    "df['Original_Weather_Category'] = df['Weather_Category']\n",
    "df = pd.get_dummies(df, columns=['Weather_Category'])\n",
    "\n",
    "\n",
    "# Keep the original Driver and Circuit for EDA\n",
    "df['Original_Driver'] = df['Driver']\n",
    "\n",
    "# Create Track temperature category based on the result of Kmeans clustering \n",
    "df['TrackTemp_Cat'] = pd.cut(df['TrackTemp'], bins=[0, 18.96764999, 27.87457484, 35.04425766, 41.75142602, 50.51006013], labels=['VERY_LOW', 'Low', 'Medium', 'Warm', 'High'])\n",
    "df['Original_TrackTemp_Cat'] = df['TrackTemp_Cat']\n",
    "df = pd.get_dummies(df, columns=['TrackTemp_Cat'])\n",
    "\n",
    "\n",
    "#Feature Engineering with weather condition features\n",
    "df['TrackConditionIndex'] = (df['WindDirection'] + df['TrackTemp'] + df['Humidity'] + df['Pressure'] ) / 4\n",
    "\n",
    "\n",
    "# One-hot encoding\n",
    "df = pd.get_dummies(df, columns=['Driver', 'Compound', 'Team','TrackStatus'])\n",
    "\n",
    "# Drop irrelevant columns\n",
    "columns_to_drop = ['Time', 'Sector1SessionTime', 'Sector2SessionTime', 'Sector3SessionTime',\n",
    "                   'PitOutTime', 'PitInTime', 'LapStartDate', 'Deleted', 'DeletedReason', 'FastF1Generated',\n",
    "                   'IsPersonalBest', 'Sector3Time','LapStartTime','Sector2Time','Sector1Time','Circuit']\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "\n",
    "# Select numerical values for scaling and imputation\n",
    "numeric_features = ['Humidity', 'Pressure', 'WindDirection', 'WindSpeed','TrackTemp','AirTemp','Rainfall','SpeedI1', 'SpeedI2', 'SpeedFL', 'SpeedST']\n",
    "\n",
    "# Example for forward fill\n",
    "#time_series_features = ['WindDirection', 'WindSpeed', 'TrackTemp', 'AirTemp', 'Rainfall', 'SpeedI1', 'SpeedI2', 'SpeedFL', 'SpeedST']\n",
    "\n",
    "df[numeric_features] = df[numeric_features].fillna(method='ffill')\n",
    "\n",
    "\n",
    "## Separate Rainy / dry days ##\n",
    "# 1. Separate LapTime as dry or wet(rainy) condition ( since lapTime of rainy day would be recognized as outliers)\n",
    "# 2. Remove Outliers for dry condition LapTime\n",
    "# 3. Build Combined LapTime df (Outliers for dry days are deleted)\n",
    "\n",
    "# Flag for rainy conditions\n",
    "df['IsRainy'] = df['Rainfall'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Separate dataframes for dry and wet conditions\n",
    "df_dry = df[df['IsRainy'] == 0]\n",
    "df_wet = df[df['IsRainy'] == 1]\n",
    "\n",
    "# Remove Outliers for dry days using the IQR method that effective to removes extreme outliers\n",
    "Q1_dry = df_dry['LapTime'].quantile(0.25)\n",
    "Q3_dry = df_dry['LapTime'].quantile(0.75)\n",
    "IQR_dry = Q3_dry - Q1_dry\n",
    "lower_bound_dry = Q1_dry - 1.5 * IQR_dry\n",
    "upper_bound_dry = Q3_dry + 1.5 * IQR_dry\n",
    "df_dry_filtered = df_dry[(df_dry['LapTime'] >= lower_bound_dry) & (df_dry['LapTime'] <= upper_bound_dry)]\n",
    "df_dry_filtered = df_dry_filtered.copy()\n",
    "df_wet = df_wet.copy()\n",
    "\n",
    "\n",
    "## Scaling to the selected numeric features ##\n",
    "robust_scaler = RobustScaler()\n",
    "\n",
    "# Applying scaling to the numeric features\n",
    "df_dry_filtered[numeric_features] = robust_scaler.fit_transform(df_dry_filtered[numeric_features])\n",
    "df_wet[numeric_features] = robust_scaler.transform(df_wet[numeric_features])  # Use transform, not fit_transform\n",
    "\n",
    "# Combining the datasets after scaling\n",
    "df_combined = pd.concat([df_dry_filtered, df_wet], ignore_index=True)\n",
    "df_combined.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_5/533f3cq93vq25vl2f3txpkb40000gn/T/ipykernel_24409/3877564752.py:16: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_combined['LapTime'].fillna(method='ffill', inplace=True)\n",
      "/var/folders/_5/533f3cq93vq25vl2f3txpkb40000gn/T/ipykernel_24409/3877564752.py:17: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_combined['Position'].fillna(method='ffill', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RMSE for Combined df: 1.7802496677052293\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from xgboost import XGBRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Drop Strings columns\n",
    "df_combined = df_combined.drop(['Original_Driver', 'Original_Weather_Category', 'Original_TrackTemp_Cat'], axis=1)\n",
    "\n",
    "# Impute missing LapTime values (considering other strategy that best suits data)\n",
    "df_combined['LapTime'].fillna(method='ffill', inplace=True)\n",
    "df_combined['Position'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "\n",
    "# Define features and target\n",
    "X = df_combined.drop('LapTime', axis=1)\n",
    "y = df_combined['LapTime']\n",
    "\n",
    "\n",
    "# stratify with Rainfall to handle imbalance \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model with class weight adjustment\n",
    "xgb_model = XGBRegressor(n_estimators=500, learning_rate=0.1,random_state=42,n_jobs=-1,max_depth=7)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "predictions = xgb_model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Baseline RMSE for Combined df: {rmse}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T10:45:15.425945Z",
     "start_time": "2024-05-03T10:45:12.256933Z"
    }
   },
   "id": "e64277b12d34e8f8",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/COMS30035_labs/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model parameters is : {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n",
      "Optimised CV RMSE: 1.802\n"
     ]
    }
   ],
   "source": [
    "\n",
    "########\n",
    "\n",
    "# Initialize KFold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Defining the model : XGB\n",
    "xgb = XGBRegressor(random_state=42)\n",
    "\n",
    "# Initial Set up the hyperparameters to test in GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# Custom scorer for RMSE ##gpt used ##\n",
    "neg_rmse_scorer = make_scorer(mean_squared_error, greater_is_better=False, squared=False)\n",
    "\n",
    "# Setup GridSearchCV with multiple scoring metrics\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=kf,\n",
    "                           scoring={'RMSE': neg_rmse_scorer},\n",
    "                           refit='RMSE',n_jobs=-1)\n",
    "grid_search.fit(X, y)  # Make sure to fit on scaled X to maintain consistency\n",
    "\n",
    "# Get the best model and print results\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_rmse = -grid_search.cv_results_['mean_test_RMSE'][grid_search.best_index_]\n",
    "\n",
    "print(\"Best model parameters is :\", best_params)\n",
    "\n",
    "print(f\"Optimised CV RMSE: {best_rmse:.3f}\")\n",
    "\n",
    "\n",
    "#from sklearn.experimental import enable_iterative_imputer\n",
    "#from sklearn.impute import IterativeImputer\n",
    "# Use IterativeImputer for more sophisticated imputation\n",
    "#iterative_imputer = IterativeImputer(random_state=42)\n",
    "#df_combined[numeric_features] = iterative_imputer.fit_transform(df_combined[numeric_features])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T10:35:19.379826Z",
     "start_time": "2024-05-03T10:33:49.141066Z"
    }
   },
   "id": "1d708ca34cbdf0c3",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_5/533f3cq93vq25vl2f3txpkb40000gn/T/ipykernel_24409/4202484053.py:16: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_combined['LapTime'].fillna(method='ffill', inplace=True)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Original_Driver', 'Original_Weather_Category', 'Original_TrackTemp_Cat'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 20\u001B[0m\n\u001B[1;32m     17\u001B[0m df_combined[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPosition\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mfillna(df_combined[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPosition\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mmean(), inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# Assuming df_combined is already loaded and processed\u001B[39;00m\n\u001B[0;32m---> 20\u001B[0m df_combined \u001B[38;5;241m=\u001B[39m \u001B[43mdf_combined\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mOriginal_Driver\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mOriginal_Weather_Category\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mOriginal_TrackTemp_Cat\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m train_years \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m2019\u001B[39m, \u001B[38;5;241m2020\u001B[39m,\u001B[38;5;241m2021\u001B[39m,\u001B[38;5;241m2022\u001B[39m]\n\u001B[1;32m     23\u001B[0m test_year \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2023\u001B[39m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/COMS30035_labs/lib/python3.11/site-packages/pandas/core/frame.py:5344\u001B[0m, in \u001B[0;36mDataFrame.drop\u001B[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[1;32m   5196\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdrop\u001B[39m(\n\u001B[1;32m   5197\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   5198\u001B[0m     labels: IndexLabel \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   5205\u001B[0m     errors: IgnoreRaise \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   5206\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   5207\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   5208\u001B[0m \u001B[38;5;124;03m    Drop specified labels from rows or columns.\u001B[39;00m\n\u001B[1;32m   5209\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   5342\u001B[0m \u001B[38;5;124;03m            weight  1.0     0.8\u001B[39;00m\n\u001B[1;32m   5343\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 5344\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   5345\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5346\u001B[0m \u001B[43m        \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5347\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5348\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5349\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5350\u001B[0m \u001B[43m        \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minplace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5351\u001B[0m \u001B[43m        \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5352\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/COMS30035_labs/lib/python3.11/site-packages/pandas/core/generic.py:4711\u001B[0m, in \u001B[0;36mNDFrame.drop\u001B[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[1;32m   4709\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m axis, labels \u001B[38;5;129;01min\u001B[39;00m axes\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m   4710\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m labels \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 4711\u001B[0m         obj \u001B[38;5;241m=\u001B[39m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_drop_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4713\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inplace:\n\u001B[1;32m   4714\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_inplace(obj)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/COMS30035_labs/lib/python3.11/site-packages/pandas/core/generic.py:4753\u001B[0m, in \u001B[0;36mNDFrame._drop_axis\u001B[0;34m(self, labels, axis, level, errors, only_slice)\u001B[0m\n\u001B[1;32m   4751\u001B[0m         new_axis \u001B[38;5;241m=\u001B[39m axis\u001B[38;5;241m.\u001B[39mdrop(labels, level\u001B[38;5;241m=\u001B[39mlevel, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[1;32m   4752\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 4753\u001B[0m         new_axis \u001B[38;5;241m=\u001B[39m \u001B[43maxis\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4754\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m axis\u001B[38;5;241m.\u001B[39mget_indexer(new_axis)\n\u001B[1;32m   4756\u001B[0m \u001B[38;5;66;03m# Case for non-unique axis\u001B[39;00m\n\u001B[1;32m   4757\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/COMS30035_labs/lib/python3.11/site-packages/pandas/core/indexes/base.py:7000\u001B[0m, in \u001B[0;36mIndex.drop\u001B[0;34m(self, labels, errors)\u001B[0m\n\u001B[1;32m   6998\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mask\u001B[38;5;241m.\u001B[39many():\n\u001B[1;32m   6999\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m-> 7000\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlabels[mask]\u001B[38;5;241m.\u001B[39mtolist()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not found in axis\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   7001\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m indexer[\u001B[38;5;241m~\u001B[39mmask]\n\u001B[1;32m   7002\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdelete(indexer)\n",
      "\u001B[0;31mKeyError\u001B[0m: \"['Original_Driver', 'Original_Weather_Category', 'Original_TrackTemp_Cat'] not found in axis\""
     ]
    }
   ],
   "source": [
    "## FOR other year - TEST ##\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from xgboost import XGBRegressor\n",
    "import shap\n",
    "\n",
    "\n",
    "\n",
    "# Impute missing LapTime values (considering other strategy that best suits data)\n",
    "df_combined['LapTime'].fillna(method='ffill', inplace=True)\n",
    "df_combined['Position'].fillna(df_combined['Position'].mean(), inplace=True)\n",
    "\n",
    "# Assuming df_combined is already loaded and processed\n",
    "df_combined = df_combined.drop(['Original_Driver', 'Original_Weather_Category', 'Original_TrackTemp_Cat'], axis=1)\n",
    "\n",
    "train_years = [2019, 2020,2021,2022]\n",
    "test_year = 2023\n",
    "\n",
    "# Split data based on year\n",
    "X_train = df_combined[df_combined['Year'].isin(train_years)].drop(['LapTime', 'Year'], axis=1)\n",
    "y_train = df_combined[df_combined['Year'].isin(train_years)]['LapTime']\n",
    "X_test = df_combined[df_combined['Year'] == test_year].drop(['LapTime', 'Year'], axis=1)\n",
    "y_test = df_combined[df_combined['Year'] == test_year]['LapTime']\n",
    "\n",
    "\n",
    "# Stage 2 : Initialize KFold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Defining the model: XGBRegressor\n",
    "xgb = XGBRegressor(random_state=42)\n",
    "\n",
    "# Setup the hyperparameters to test in GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# Custom scorer for RMSE\n",
    "neg_rmse_scorer = make_scorer(mean_squared_error, greater_is_better=False, squared=False)\n",
    "\n",
    "# Setup GridSearchCV with multiple scoring metrics\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=kf,\n",
    "                           scoring={'RMSE': neg_rmse_scorer},\n",
    "                           refit='RMSE', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model and print results\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "best_rmse = -grid_search.cv_results_['mean_test_RMSE'][grid_search.best_index_]\n",
    "\n",
    "print(\"Best model parameters:\", best_params)\n",
    "print(f\"Optimised CV RMSE: {best_rmse:.3f}\")\n",
    "\n",
    "# Use SHAP to explain feature importance\n",
    "explainer = shap.Explainer(best_model)\n",
    "shap_values = explainer(X_train)\n",
    "\n",
    "# Plot feature importance\n",
    "shap.summary_plot(shap_values, X_train, feature_names=X_train.columns)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T10:35:19.988093Z",
     "start_time": "2024-05-03T10:35:19.381197Z"
    }
   },
   "id": "c0713fd3168d186c",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\"\"\"shap_sum = np.abs(shap_values.values).mean(axis=0)\n",
    "feature_importance = pd.Series(shap_sum, index=X_train.columns)\n",
    "\n",
    "# Sort the features by their mean absolute SHAP value in descending order\n",
    "sorted_feature_importance = feature_importance.sort_values(ascending=False)\n",
    "\n",
    "# Display the sorted features with their importance\n",
    "print(sorted_feature_importance)\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T10:35:19.989133Z",
     "start_time": "2024-05-03T10:35:19.989078Z"
    }
   },
   "id": "6f8e822aad0ad41f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found a NULL input array in _cext_dense_tree_update_weights!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot cast array data from dtype('O') to dtype('float64') according to the rule 'safe'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 8\u001B[0m\n\u001B[1;32m      5\u001B[0m model \u001B[38;5;241m=\u001B[39m xgb\u001B[38;5;241m.\u001B[39mXGBRegressor()\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# Explainer\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m explainer \u001B[38;5;241m=\u001B[39m \u001B[43mshap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mExplainer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m shap_values \u001B[38;5;241m=\u001B[39m explainer\u001B[38;5;241m.\u001B[39mshap_values(X_train)\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# Plotting SHAP summary plot\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/COMS30035_labs/lib/python3.11/site-packages/shap/explainers/_explainer.py:188\u001B[0m, in \u001B[0;36mExplainer.__init__\u001B[0;34m(self, model, masker, link, algorithm, output_names, feature_names, linearize_link, seed, **kwargs)\u001B[0m\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m algorithm \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtree\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    187\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m \u001B[38;5;241m=\u001B[39m explainers\u001B[38;5;241m.\u001B[39mTreeExplainer\n\u001B[0;32m--> 188\u001B[0m     \u001B[43mexplainers\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTreeExplainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmasker\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlink\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlink\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeature_names\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlinearize_link\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlinearize_link\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    189\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m algorithm \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124madditive\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    190\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m \u001B[38;5;241m=\u001B[39m explainers\u001B[38;5;241m.\u001B[39mAdditiveExplainer\n",
      "File \u001B[0;32m/opt/anaconda3/envs/COMS30035_labs/lib/python3.11/site-packages/shap/explainers/_tree.py:195\u001B[0m, in \u001B[0;36mTreeExplainer.__init__\u001B[0;34m(self, model, data, model_output, feature_perturbation, feature_names, approximate, link, linearize_link)\u001B[0m\n\u001B[1;32m    193\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_perturbation \u001B[38;5;241m=\u001B[39m feature_perturbation\n\u001B[1;32m    194\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexpected_value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 195\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[43mTreeEnsemble\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_missing\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_output\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_output \u001B[38;5;241m=\u001B[39m model_output\n\u001B[1;32m    197\u001B[0m \u001B[38;5;66;03m#self.model_output = self.model.model_output # this allows the TreeEnsemble to translate model outputs types by how it loads the model\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/COMS30035_labs/lib/python3.11/site-packages/shap/explainers/_tree.py:1090\u001B[0m, in \u001B[0;36mTreeEnsemble.__init__\u001B[0;34m(self, model, data, data_missing, model_output)\u001B[0m\n\u001B[1;32m   1088\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m safe_isinstance(model, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxgboost.sklearn.XGBRegressor\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m   1089\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moriginal_model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mget_booster()\n\u001B[0;32m-> 1090\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_set_xgboost_model_attributes\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1091\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1092\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata_missing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1093\u001B[0m \u001B[43m        \u001B[49m\u001B[43mobjective_name_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1094\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtree_output_name_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1095\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1096\u001B[0m     \u001B[38;5;66;03m# Some properties of the sklearn API are passed to a DMatrix object in\u001B[39;00m\n\u001B[1;32m   1097\u001B[0m     \u001B[38;5;66;03m# xgboost We need to make sure we do the same here - GH #3313\u001B[39;00m\n\u001B[1;32m   1098\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_xgb_dmatrix_props \u001B[38;5;241m=\u001B[39m get_xgboost_dmatrix_properties(model)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/COMS30035_labs/lib/python3.11/site-packages/shap/explainers/_tree.py:1317\u001B[0m, in \u001B[0;36mTreeEnsemble._set_xgboost_model_attributes\u001B[0;34m(self, data, data_missing, objective_name_map, tree_output_name_map)\u001B[0m\n\u001B[1;32m   1314\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_type \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxgboost\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1315\u001B[0m loader \u001B[38;5;241m=\u001B[39m XGBTreeModelLoader(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moriginal_model)\n\u001B[0;32m-> 1317\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrees \u001B[38;5;241m=\u001B[39m \u001B[43mloader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_trees\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_missing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_missing\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1318\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_offset \u001B[38;5;241m=\u001B[39m loader\u001B[38;5;241m.\u001B[39mbase_score\n\u001B[1;32m   1319\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobjective \u001B[38;5;241m=\u001B[39m objective_name_map\u001B[38;5;241m.\u001B[39mget(loader\u001B[38;5;241m.\u001B[39mname_obj, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/COMS30035_labs/lib/python3.11/site-packages/shap/explainers/_tree.py:2028\u001B[0m, in \u001B[0;36mXGBTreeModelLoader.get_trees\u001B[0;34m(self, data, data_missing)\u001B[0m\n\u001B[1;32m   2018\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_trees):\n\u001B[1;32m   2019\u001B[0m     info \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m   2020\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchildren_left\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnode_cleft[i],\n\u001B[1;32m   2021\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchildren_right\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnode_cright[i],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2026\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnode_sample_weight\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msum_hess[i],\n\u001B[1;32m   2027\u001B[0m     }\n\u001B[0;32m-> 2028\u001B[0m     trees\u001B[38;5;241m.\u001B[39mappend(\u001B[43mSingleTree\u001B[49m\u001B[43m(\u001B[49m\u001B[43minfo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_missing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_missing\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   2029\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m trees\n",
      "File \u001B[0;32m/opt/anaconda3/envs/COMS30035_labs/lib/python3.11/site-packages/shap/explainers/_tree.py:1760\u001B[0m, in \u001B[0;36mSingleTree.__init__\u001B[0;34m(self, tree, normalize, scaling, data, data_missing)\u001B[0m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m data_missing \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1759\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnode_sample_weight\u001B[38;5;241m.\u001B[39mfill(\u001B[38;5;241m0.0\u001B[39m)\n\u001B[0;32m-> 1760\u001B[0m     \u001B[43m_cext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdense_tree_update_weights\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1761\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchildren_left\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchildren_right\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchildren_default\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1762\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mthresholds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnode_sample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_missing\u001B[49m\n\u001B[1;32m   1763\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1765\u001B[0m \u001B[38;5;66;03m# we compute the expectations to make sure they follow the SHAP logic\u001B[39;00m\n\u001B[1;32m   1766\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_depth \u001B[38;5;241m=\u001B[39m _cext\u001B[38;5;241m.\u001B[39mcompute_expectations(\n\u001B[1;32m   1767\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren_left, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren_right, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnode_sample_weight,\n\u001B[1;32m   1768\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalues\n\u001B[1;32m   1769\u001B[0m )\n",
      "\u001B[0;31mTypeError\u001B[0m: Cannot cast array data from dtype('O') to dtype('float64') according to the rule 'safe'"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import xgboost as xgb\n",
    "\n",
    "# Assuming X_train and model are already defined and trained\n",
    "model = xgb.XGBRegressor().fit(X_train, y_train)\n",
    "\n",
    "# Explainer\n",
    "explainer = shap.Explainer(model, X_train)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "# Plotting SHAP summary plot\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T10:38:47.323176Z",
     "start_time": "2024-05-03T10:38:46.037118Z"
    }
   },
   "id": "f8bbe90851f54375",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame with 'lap_time', 'temperature', and 'humidity'\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(df_combined['TrackTemp'], df_combined['lap_time'], c='blue', label='TrackTemp')\n",
    "plt.scatter(df_combined['humidity'], df_combined['lap_time'], c='red', label='Humidity')\n",
    "plt.title('Impact of Temperature and Humidity on Lap Times')\n",
    "plt.xlabel('Weather Condition')\n",
    "plt.ylabel('Lap Time')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17f2b59eeb5335a6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e5d4299367e65cb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8039c42344cce157",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3d1c6b58fcf60b20"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
