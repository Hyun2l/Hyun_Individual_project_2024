{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-04T13:50:26.827694Z",
     "start_time": "2024-05-04T13:50:26.825693Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_5/533f3cq93vq25vl2f3txpkb40000gn/T/ipykernel_28988/4217210953.py:75: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[numeric_features] = df[numeric_features].fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "#1 IQR both\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('f1_2019_to_2023_all_drivers_all_data.csv', low_memory=False)\n",
    "\n",
    "# Convert time columns to seconds\n",
    "time_columns = ['LapTime', 'Sector1Time', 'Sector2Time', 'Sector3Time','Time']\n",
    "for col in time_columns:\n",
    "    df[col] = pd.to_timedelta(df[col]).dt.total_seconds()\n",
    "\n",
    "# Convert binary columns to integer type\n",
    "df['Rainfall'] = df['Rainfall'].astype(int)\n",
    "df['FreshTyre'] = df['FreshTyre'].astype(int)\n",
    "df['IsAccurate'] = df['IsAccurate'].astype(int)\n",
    "\n",
    "\n",
    "# Categorize weather condition based on centroid values of Kmeans clustering\n",
    "def categorize_weather(row):\n",
    "    if row['Rainfall'] > 0:\n",
    "        return 'Rainy'\n",
    "    elif row['AirTemp'] > 28.43213126:\n",
    "        return 'high'\n",
    "    elif row['AirTemp'] > 21.31279265:\n",
    "        return 'medium'\n",
    "    elif row['AirTemp'] > 12.84901403:\n",
    "        return 'low'\n",
    "    else:\n",
    "        return 'very_low'\n",
    "df['Weather_Category'] = df.apply(categorize_weather, axis=1)\n",
    "df = pd.get_dummies(df, columns=['Weather_Category'])\n",
    "\n",
    "\n",
    "\n",
    "# Create Track temperature category based on the result of Kmeans clustering \n",
    "df['TrackTemp_Cat'] = pd.cut(df['TrackTemp'], bins=[0, 18.96764999, 27.87457484, 35.04425766, 41.75142602, 50.51006013, 53.02449646], labels=['VERY_LOW', 'Low', 'Medium', 'Warm', 'High','VERY_High'])\n",
    "df = pd.get_dummies(df, columns=['TrackTemp_Cat'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# One-hot encoding\n",
    "df = pd.get_dummies(df, columns=['Driver', 'Compound', 'Team','TrackStatus','Circuit'])\n",
    "# Drop irrelevant columns\n",
    "columns_to_drop = ['Sector1SessionTime', 'Sector2SessionTime', 'Sector3SessionTime',\n",
    "                   'PitOutTime', 'PitInTime', 'LapStartDate', 'Deleted', 'DeletedReason', 'FastF1Generated',\n",
    "                   'IsPersonalBest', 'Sector3Time','LapStartTime','Sector2Time','Sector1Time']\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Select numerical values for scaling and imputation\n",
    "numeric_features = ['Humidity', 'Pressure', 'WindDirection', 'WindSpeed','TrackTemp','AirTemp','SpeedI1', 'SpeedI2', 'SpeedFL', 'SpeedST']\n",
    "\n",
    "# Example for forward fill\n",
    "#time_series_features = ['WindDirection', 'WindSpeed', 'TrackTemp', 'AirTemp', 'Rainfall', 'SpeedI1', 'SpeedI2', 'SpeedFL', 'SpeedST']\n",
    "\n",
    "df[numeric_features] = df[numeric_features].fillna(method='ffill')\n",
    "\n",
    "\n",
    "## Separate Rainy / dry days ##\n",
    "# 1. Separate LapTime as dry or wet(rainy) condition ( since lapTime of rainy day would be recognized as outliers)\n",
    "# 2. Remove Outliers for dry condition LapTime\n",
    "# 3. Build Combined LapTime df (Outliers for dry days are deleted)\n",
    "\n",
    "# Flag for rainy conditions\n",
    "df['IsRainy'] = df['Rainfall'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Separate dataframes for dry and wet conditions\n",
    "df_dry = df[df['IsRainy'] == 0]\n",
    "df_wet = df[df['IsRainy'] == 1]\n",
    "\n",
    "def remove_outliers(df, column_name, multiplier=1.5):\n",
    "    Q1 = df[column_name].quantile(0.25)\n",
    "    Q3 = df[column_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - multiplier * IQR\n",
    "    upper_bound = Q3 + multiplier * IQR\n",
    "    return df[(df[column_name] >= lower_bound) & (df[column_name] <= upper_bound)]\n",
    "\n",
    "# Apply standard IQR for dry days\n",
    "df_dry_filtered = remove_outliers(df_dry, 'LapTime', multiplier=1.5)\n",
    "\n",
    "# Apply a more lenient IQR for wet days\n",
    "df_wet_filtered = remove_outliers(df_wet, 'LapTime', multiplier=2.0)\n",
    "\n",
    "\n",
    "df_combined = pd.concat([df_dry_filtered, df_wet_filtered], ignore_index=True)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "#fit sclaer\n",
    "df_combined[numeric_features] = scaler.fit_transform(df_combined[numeric_features])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T13:50:29.122796Z",
     "start_time": "2024-05-04T13:50:26.829509Z"
    }
   },
   "id": "fb60d707ed115f8c",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RMSE for Combined df: 3.5400348933251977\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
    "from pytorch_forecasting.data.encoders import NaNLabelEncoder\n",
    "\n",
    "\n",
    "# Assuming df_combined is already loaded and preprocessed\n",
    "df_combined['time_idx'] = (df_combined.index - df_combined.index.min())\n",
    "\n",
    "# Setup TimeSeriesDataSet\n",
    "max_encoder_length = 36\n",
    "max_prediction_length = 6\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    df_combined,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"LapTime\",\n",
    "    group_ids=[\"IsRainy\"],\n",
    "    min_encoder_length=max_encoder_length,\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=max_prediction_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[\"IsRainy\"],\n",
    "    time_varying_known_reals=numeric_features + [f'lag_{i}' for i in range(1, 25)],\n",
    "    target_normalizer=None,  # Already scaled\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True\n",
    ")\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 16\n",
    "train_dataloader = DataLoader(training, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(training.to_dataloader(), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define and train the Temporal Fusion Transformer\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    output_size=1,\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "from pytorch_forecasting import Trainer, EarlyStopping\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=20,\n",
    "    gpus=0,  # Adjust based on your GPU availability\n",
    "    limit_train_batches=30,  # Model on a subset of data for quick training\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloaders=val_dataloader\n",
    ")\n",
    "\n",
    "# Note: You can adjust the model parameters and training setup based on your dataset size and complexity.\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T13:56:57.415989Z",
     "start_time": "2024-05-04T13:56:56.767324Z"
    }
   },
   "id": "68b65078f4fcbf56",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T13:52:28.324282Z",
     "start_time": "2024-05-04T13:52:28.321649Z"
    }
   },
   "id": "c480b1dac2180272",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T13:54:16.702785Z",
     "start_time": "2024-05-04T13:54:16.701329Z"
    }
   },
   "id": "eceb962b6aad9499",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "effb27673765538"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
